"""
RAG MCP Server - HTTP/SSE Version
FastAPIë¥¼ ì‚¬ìš©í•œ HTTP í†µì‹  ì§€ì› MCP ì„œë²„
"""

from dotenv import load_dotenv
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

"""
RAG MCP Server - HTTP/SSE Version
FastAPIë¥¼ ì‚¬ìš©í•œ HTTP í†µì‹  ì§€ì› MCP ì„œë²„
"""

import asyncio
import os
from typing import Any, Optional
from contextlib import asynccontextmanager
import json

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

from mcp.server import Server
from mcp.types import Tool, TextContent
import anthropic
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# ì „ì—­ ë³€ìˆ˜
vectorstore: Optional[Chroma] = None
anthropic_client: Optional[anthropic.Anthropic] = None
mcp_server: Optional[Server] = None
tools_list_handler = None
call_tool_handler = None
PERSIST_DIRECTORY = "./chroma_db"
COLLECTION_NAME = "rag_documents"

def initialize_vectorstore():
    """ChromaDB vectorstore ì´ˆê¸°í™”"""
    global vectorstore
    
    print("ğŸ”§ Initializing vectorstore...")
    
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        #model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embeddings,
        collection_name=COLLECTION_NAME
    )
    
    print("âœ… Vectorstore initialized")
    return vectorstore


def initialize_claude():
    """Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global anthropic_client
    
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY not set. RAG query feature will be disabled.")
        return None
    
    anthropic_client = anthropic.Anthropic(api_key=api_key)
    print("âœ… Claude API client initialized")
    return anthropic_client


def initialize_mcp_server():
    """MCP ì„œë²„ ì´ˆê¸°í™”"""
    global mcp_server, tools_list_handler, call_tool_handler
    
    mcp_server = Server("rag-search-server")
    
    @mcp_server.list_tools()
    async def list_tools() -> list[Tool]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return [
            Tool(
                name="add_documents",
                description="Add documents to the vector database with automatic chunking and embedding.",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "texts": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Array of document texts to add"
                        },
                        "metadatas": {
                            "type": "array",
                            "items": {"type": "object"},
                            "description": "Optional array of metadata objects"
                        },
                        "chunk_size": {
                            "type": "integer",
                            "description": "Chunk size (default: 1000)",
                            "default": 1000
                        },
                        "chunk_overlap": {
                            "type": "integer",
                            "description": "Chunk overlap (default: 200)",
                            "default": 200
                        }
                    },
                    "required": ["texts"]
                }
            ),
            Tool(
                name="search_documents",
                description="Search for similar documents in the vector database.",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "Search query"
                        },
                        "k": {
                            "type": "integer",
                            "description": "Number of results (default: 4)",
                            "default": 4
                        }
                    },
                    "required": ["query"]
                }
            ),
            Tool(
                name="rag_query",
                description="Answer questions using RAG with Claude AI.",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "question": {
                            "type": "string",
                            "description": "Question to answer"
                        },
                        "k": {
                            "type": "integer",
                            "description": "Number of documents to retrieve (default: 4)",
                            "default": 4
                        },
                        "language": {
                            "type": "string",
                            "description": "Response language (ko/en, default: ko)",
                            "default": "ko"
                        }
                    },
                    "required": ["question"]
                }
            ),
            Tool(
                name="get_collection_info",
                description="Get information about the current collection.",
                inputSchema={
                    "type": "object",
                    "properties": {}
                }
            ),
            Tool(
                name="delete_collection",
                description="Delete the entire collection (WARNING: irreversible).",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "confirm": {
                            "type": "boolean",
                            "description": "Must be true to confirm deletion"
                        }
                    },
                    "required": ["confirm"]
                }
            )
        ]
    
    @mcp_server.call_tool()
    async def call_tool(name: str, arguments: Any) -> list[TextContent]:
        """ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬"""
        if vectorstore is None:
            initialize_vectorstore()
        
        try:
            if name == "add_documents":
                return await add_documents_handler(arguments)
            elif name == "search_documents":
                return await search_documents_handler(arguments)
            elif name == "rag_query":
                return await rag_query_handler(arguments)
            elif name == "get_collection_info":
                return await get_collection_info_handler(arguments)
            elif name == "delete_collection":
                return await delete_collection_handler(arguments)
            else:
                return [TextContent(type="text", text=f"Unknown tool: {name}")]
        except Exception as e:
            return [TextContent(type="text", text=f"Error executing {name}: {str(e)}")]
    
    # í•¸ë“¤ëŸ¬ë¥¼ ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
    global tools_list_handler, call_tool_handler
    tools_list_handler = list_tools
    call_tool_handler = call_tool
    
    print("âœ… MCP server initialized")
    return mcp_server


async def add_documents_handler(arguments: dict) -> list[TextContent]:
    """ë¬¸ì„œ ì¶”ê°€ í•¸ë“¤ëŸ¬"""
    texts = arguments.get("texts", [])
    metadatas = arguments.get("metadatas", [{}] * len(texts))
    chunk_size = arguments.get("chunk_size", 1000)
    chunk_overlap = arguments.get("chunk_overlap", 200)
    
    if not texts:
        return [TextContent(type="text", text="Error: No texts provided")]
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        separators=["\n\n", "\n", " ", ""]
    )
    
    documents = []
    for i, text in enumerate(texts):
        chunks = text_splitter.split_text(text)
        metadata = metadatas[i] if i < len(metadatas) else {}
        
        for j, chunk in enumerate(chunks):
            doc = Document(
                page_content=chunk,
                metadata={**metadata, "chunk_index": j, "total_chunks": len(chunks)}
            )
            documents.append(doc)
    
    vectorstore.add_documents(documents)
    
    return [TextContent(
        type="text",
        text=f"âœ… Successfully added {len(documents)} document chunks from {len(texts)} documents\n"
             f"   Chunk size: {chunk_size}, Overlap: {chunk_overlap}"
    )]


async def search_documents_handler(arguments: dict) -> list[TextContent]:
    """ë¬¸ì„œ ê²€ìƒ‰ í•¸ë“¤ëŸ¬"""
    query = arguments.get("query", "")
    k = arguments.get("k", 4)
    
    if not query:
        return [TextContent(type="text", text="Error: No query provided")]
    
    results = vectorstore.similarity_search(query, k=k)
    
    if not results:
        return [TextContent(type="text", text="No documents found matching your query.")]
    
    formatted_results = [f"ğŸ” Found {len(results)} documents:\n"]
    
    for i, doc in enumerate(results, 1):
        metadata_str = ", ".join([f"{k}: {v}" for k, v in doc.metadata.items()])
        formatted_results.append(
            f"\nğŸ“„ Document {i}:\n"
            f"Content: {doc.page_content[:200]}{'...' if len(doc.page_content) > 200 else ''}\n"
            f"Metadata: {metadata_str}\n"
        )
    
    return [TextContent(type="text", text="".join(formatted_results))]


async def rag_query_handler(arguments: dict) -> list[TextContent]:
    """RAG ì¿¼ë¦¬ í•¸ë“¤ëŸ¬"""
    global anthropic_client
    
    question = arguments.get("question", "")
    k = arguments.get("k", 4)
    language = arguments.get("language", "ko")
    
    if not question:
        return [TextContent(type="text", text="Error: No question provided")]
    
    if anthropic_client is None:
        try:
            initialize_claude()
        except:
            pass
        
        if anthropic_client is None:
            return [TextContent(type="text", text="Error: ANTHROPIC_API_KEY not configured")]
    
    relevant_docs = vectorstore.similarity_search(question, k=k)
    
    if not relevant_docs:
        return [TextContent(type="text", text="âŒ No relevant documents found in the database.")]
    
    context = "\n\n".join([
        f"[Document {i+1}]\n{doc.page_content}"
        for i, doc in enumerate(relevant_docs)
    ])
    
    if language == "ko":
        prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ìœ„ ë¬¸ì„œë“¤ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
    else:
        prompt = f"""Please answer the question based on the following documents.

Reference Documents:
{context}

Question: {question}

Please provide an accurate and detailed answer based on the information above."""

    try:
        message = anthropic_client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        answer = message.content[0].text
        
        sources = "\n\n" + "="*60 + "\nğŸ“š Referenced Documents:\n"
        for i, doc in enumerate(relevant_docs, 1):
            metadata_items = [f"{k}: {v}" for k, v in doc.metadata.items() 
                            if k not in ['chunk_index', 'total_chunks']]
            metadata_str = ", ".join(metadata_items) if metadata_items else "No metadata"
            preview = doc.page_content[:100].replace('\n', ' ')
            sources += f"  [{i}] {metadata_str}\n      Preview: {preview}...\n"
        
        return [TextContent(type="text", text=f"ğŸ’¡ Answer:\n\n{answer}{sources}")]
    
    except Exception as e:
        return [TextContent(type="text", text=f"Error generating answer: {str(e)}")]


async def get_collection_info_handler(arguments: dict) -> list[TextContent]:
    """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
    try:
        collection = vectorstore._collection
        count = collection.count()
        
        info = f"""ğŸ“Š Collection Information:

Collection Name: {collection.name}
Total Documents: {count}
Persist Directory: {PERSIST_DIRECTORY}
Embedding Model: sentence-transformers/all-MiniLM-L6-v2
"""
        return [TextContent(type="text", text=info)]
    except Exception as e:
        return [TextContent(type="text", text=f"Error getting collection info: {str(e)}")]


async def delete_collection_handler(arguments: dict) -> list[TextContent]:
    """ì»¬ë ‰ì…˜ ì‚­ì œ"""
    global vectorstore
    
    confirm = arguments.get("confirm", False)
    
    if not confirm:
        return [TextContent(
            type="text",
            text="âš ï¸  Deletion cancelled. Set 'confirm' to true to delete the collection."
        )]
    
    try:
        vectorstore.delete_collection()
        initialize_vectorstore()
        return [TextContent(type="text", text="âœ… Collection successfully deleted and reinitialized.")]
    except Exception as e:
        return [TextContent(type="text", text=f"Error deleting collection: {str(e)}")]


# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸš€ RAG MCP Server (HTTP/SSE) Starting...")
    print("=" * 60)
    
    # ì´ˆê¸°í™”
    initialize_vectorstore()
    initialize_claude()
    initialize_mcp_server()
    
    print("\nâœ… Server ready!")
    print(f"ğŸ“¡ Listening on http://0.0.0.0:8000")
    print(f"ğŸ”§ SSE endpoint: http://0.0.0.0:8000/sse")
    print("=" * 60 + "\n")
    
    yield
    
    print("\nğŸ‘‹ Shutting down...")


app = FastAPI(
    title="RAG MCP Server",
    description="HTTP/SSE based MCP server for RAG operations",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """ëª¨ë“  ìš”ì²­ ë¡œê¹…"""
    if request.url.path == "/sse":
        try:
            body = await request.body()
            body_str = body.decode('utf-8')
            print(f"ğŸ“¥ Received: {body_str[:200]}")
            
            # bodyë¥¼ ë‹¤ì‹œ ì½ì„ ìˆ˜ ìˆë„ë¡ ì„¤ì •
            async def receive():
                return {"type": "http.request", "body": body}
            
            request._receive = receive
        except:
            pass
    
    response = await call_next(request)
    return response


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "name": "RAG MCP Server",
        "version": "1.0.0",
        "endpoints": {
            "sse": "/sse",
            "health": "/health",
            "tools": "/tools"
        }
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "vectorstore": vectorstore is not None,
        "claude_client": anthropic_client is not None,
        "mcp_server": mcp_server is not None
    }


@app.get("/tools")
async def get_tools():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
    if tools_list_handler is None:
        raise HTTPException(status_code=500, detail="MCP server not initialized")
    
    # list_tools í•¸ë“¤ëŸ¬ í˜¸ì¶œ
    tools = await tools_list_handler()
    
    return {
        "tools": [
            {
                "name": tool.name,
                "description": tool.description,
                "inputSchema": tool.inputSchema
            }
            for tool in tools
        ]
    }


@app.post("/sse")
async def sse_endpoint(request: Request):
    """SSE (Server-Sent Events) ì—”ë“œí¬ì¸íŠ¸ - MCP í”„ë¡œí† ì½œ"""
    
    body = None
    try:
        body = await request.json()
        
        # idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (MCP í”„ë¡œí† ì½œ í˜¸í™˜ì„±)
        msg_id = str(body.get("id", "0")) if body.get("id") is not None else "0"
        method = body.get("method", "")
        
        # MCP ë©”ì‹œì§€ ì²˜ë¦¬
        if method == "initialize":
            # MCP ì´ˆê¸°í™” í•¸ë“œì…°ì´í¬
            response = {
                "jsonrpc": "2.0",
                "id": msg_id,
                "result": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "tools": {}
                    },
                    "serverInfo": {
                        "name": "rag-search-server",
                        "version": "1.0.0"
                    }
                }
            }
            return JSONResponse(content=response)
        
        elif method == "notifications/initialized":
            # ì´ˆê¸°í™” ì™„ë£Œ ì•Œë¦¼ (ì‘ë‹µ ë¶ˆí•„ìš”)
            return JSONResponse(content={"jsonrpc": "2.0"})
        
        elif method == "tools/list":
            tools = await tools_list_handler()
            response = {
                "jsonrpc": "2.0",
                "id": msg_id,
                "result": {
                    "tools": [
                        {
                            "name": tool.name,
                            "description": tool.description,
                            "inputSchema": tool.inputSchema
                        }
                        for tool in tools
                    ]
                }
            }
            return JSONResponse(content=response)
        
        elif method == "tools/call":
            params = body.get("params", {})
            name = params.get("name")
            arguments = params.get("arguments", {})
            
            result = await call_tool_handler(name, arguments)
            
            response = {
                "jsonrpc": "2.0",
                "id": msg_id,
                "result": {
                    "content": [
                        {
                            "type": content.type,
                            "text": content.text
                        }
                        for content in result
                    ]
                }
            }
            return JSONResponse(content=response)
        
        elif method.startswith("notifications/"):
            # ì•Œë¦¼ ë©”ì‹œì§€ (ì‘ë‹µ ë¶ˆí•„ìš”)
            return JSONResponse(content={"jsonrpc": "2.0"})
        
        else:
            error_response = {
                "jsonrpc": "2.0",
                "id": msg_id,
                "error": {
                    "code": -32601,
                    "message": f"Method not found: {method}"
                }
            }
            return JSONResponse(content=error_response, status_code=400)
    
    except json.JSONDecodeError as e:
        error_response = {
            "jsonrpc": "2.0",
            "id": "0",
            "error": {
                "code": -32700,
                "message": f"Parse error: {str(e)}"
            }
        }
        return JSONResponse(content=error_response, status_code=400)
    
    except Exception as e:
        msg_id = "0"
        if body and isinstance(body, dict):
            msg_id = str(body.get("id", "0")) if body.get("id") is not None else "0"
        
        error_response = {
            "jsonrpc": "2.0",
            "id": msg_id,
            "error": {
                "code": -32603,
                "message": f"Internal error: {str(e)}"
            }
        }
        return JSONResponse(content=error_response, status_code=500)


if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )